{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b740024d",
   "metadata": {},
   "source": [
    "1. Actor(玩家):\n",
    "\n",
    "> 为了玩转这个游戏得到尽量高的reward, 你需要实现一个函数: 输入state, 输出action, 可以用神经网络来近似这个函数\n",
    "> \n",
    "> 剩下的任务就是如何训练神经网络, 让它的表现更好(得更高的reward)\n",
    "\n",
    "2. Critic(评委): \n",
    "\n",
    "> 为了训练actor, 你需要知道actor的表现到底怎么样, 根据表现来决定对神经网络参数的调整, 这就要用到强化学习中的“Q-value”\n",
    "> \n",
    "> 但Q-value也是一个未知的函数, 所以也可以用神经网络来近似\n",
    "\n",
    "\n",
    "Actor-Critic的训练\n",
    "\n",
    "- Actor看到游戏目前的state, 做出一个action\n",
    "\n",
    "- Critic根据state和action两者, 对actor刚才的表现打一个分数\n",
    "\n",
    "- Actor依据critic(评委)的打分, 调整自己的策略(actor神经网络参数), 争取下次做得更好\n",
    "\n",
    "- Critic根据系统给出的reward(相当于ground truth)和其他评委的打分(critic target)来调整自己的打分策略(critic神经网络参数)\n",
    "\n",
    "一开始actor随机表演, critic随机打分\n",
    "\n",
    "但是由于reward的存在, critic评分越来越准, actor表现越来越好\n",
    "\n",
    "感觉有种类似 `GAN` 的感觉, 两个网络在相互的碰撞, boom!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-cigarette",
   "metadata": {},
   "source": [
    "# GCN practice code\n",
    "\n",
    "- import basic library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34d69163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.version' from 'e:\\\\conda3\\\\envs\\\\test\\\\lib\\\\site-packages\\\\torch\\\\version.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "existing-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from random import randint, expovariate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-spare",
   "metadata": {},
   "source": [
    "- Generate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4462929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_CPU_MAX = []\n",
    "S_BW_MAX = []\n",
    "\n",
    "# 随机生成一个图(20节点, 100链路)\n",
    "net = nx.gnm_random_graph(n=20, m=100)\n",
    "\n",
    "# 设置所有节点的CPU数据, 并同时统计最大值最小值\n",
    "min_cpu_capacity = 1.0e10\n",
    "max_cpu_capacity = 0.0\n",
    "for node_id in net.nodes:\n",
    "    net.nodes[node_id]['CPU'] = randint(50, 100)\n",
    "    net.nodes[node_id]['LOCATION'] = randint(0, 2)\n",
    "    \n",
    "    if net.nodes[node_id]['CPU'] < min_cpu_capacity:\n",
    "        min_cpu_capacity = net.nodes[node_id]['CPU']\n",
    "    if net.nodes[node_id]['CPU'] > max_cpu_capacity:\n",
    "        max_cpu_capacity = net.nodes[node_id]['CPU']\n",
    "\n",
    "# 设置链路的带宽数据, 并同时统计最大带宽最小带宽\n",
    "min_bandwidth_capacity = 1.0e10\n",
    "max_bandwidth_capacity = 0.0\n",
    "for edge_id in net.edges:\n",
    "    net.edges[edge_id]['bandwidth'] = randint(50, 100)\n",
    "    \n",
    "    if net.edges[edge_id]['bandwidth'] < min_bandwidth_capacity:\n",
    "        min_bandwidth_capacity = net.edges[edge_id]['bandwidth']\n",
    "    if net.edges[edge_id]['bandwidth'] > max_bandwidth_capacity:\n",
    "        max_bandwidth_capacity = net.edges[edge_id]['bandwidth']\n",
    "\n",
    "# data=True: 返回的是 NodeDataView 对象, 该对象不仅包含每个顶点的 ID 属性, 还包括顶点的其他属性\n",
    "for s_node_id, s_node_data in net.nodes(data=True):\n",
    "    S_CPU_MAX.append(s_node_data['CPU'])\n",
    "\n",
    "# 统计每个底层节点周围链路带宽和\n",
    "for s_node_id in range(len(net.nodes)):\n",
    "    total_node_bandwidth = 0.0\n",
    "    for link_id in net[s_node_id]:\n",
    "        total_node_bandwidth += net[s_node_id][link_id]['bandwidth']\n",
    "    S_BW_MAX.append(total_node_bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "promotional-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    " # S_CPU_Free\n",
    "s_CPU_remaining = []\n",
    "s_bandwidth_remaining = []\n",
    "\n",
    "# 1 表示目前哪些节点被占用, 0 相反\n",
    "current_embedding = [0] * len(net.nodes)\n",
    "\n",
    "# 节点剩余资源\n",
    "for s_node_id, s_node_data in net.nodes(data=True):\n",
    "    s_CPU_remaining.append(s_node_data['CPU'])\n",
    "    \n",
    "# 节点周围剩余带宽资源\n",
    "for s_node_id in range(len(net.nodes)):\n",
    "    total_node_bandwidth = 0.0\n",
    "    for link_id in net[s_node_id]:\n",
    "        total_node_bandwidth += net[s_node_id][link_id]['bandwidth']\n",
    "    s_bandwidth_remaining.append(total_node_bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "speaking-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52, 95, 100, 63, 96, 63, 50, 60, 60, 58, 97, 73, 58, 63, 80, 54, 51, 80, 52, 83], [727.0, 636.0, 927.0, 421.0, 932.0, 724.0, 698.0, 960.0, 482.0, 992.0, 885.0, 663.0, 824.0, 845.0, 709.0, 515.0, 552.0, 788.0, 931.0, 685.0], [52, 95, 100, 63, 96, 63, 50, 60, 60, 58, 97, 73, 58, 63, 80, 54, 51, 80, 52, 83], [727.0, 636.0, 927.0, 421.0, 932.0, 724.0, 698.0, 960.0, 482.0, 992.0, 885.0, 663.0, 824.0, 845.0, 709.0, 515.0, 552.0, 788.0, 931.0, 685.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# 底层网络特征矩阵\n",
    "substrate_features = []\n",
    "substrate_features.append(S_CPU_MAX)\n",
    "substrate_features.append(S_BW_MAX)\n",
    "\n",
    "substrate_features.append(s_CPU_remaining)\n",
    "substrate_features.append(s_bandwidth_remaining)\n",
    "\n",
    "substrate_features.append(current_embedding)\n",
    "\n",
    "print(substrate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "voluntary-favorite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 52.,  95., 100.,  63.,  96.,  63.,  50.,  60.,  60.,  58.,  97.,  73.,\n",
      "          58.,  63.,  80.,  54.,  51.,  80.,  52.,  83.],\n",
      "        [727., 636., 927., 421., 932., 724., 698., 960., 482., 992., 885., 663.,\n",
      "         824., 845., 709., 515., 552., 788., 931., 685.],\n",
      "        [ 52.,  95., 100.,  63.,  96.,  63.,  50.,  60.,  60.,  58.,  97.,  73.,\n",
      "          58.,  63.,  80.,  54.,  51.,  80.,  52.,  83.],\n",
      "        [727., 636., 927., 421., 932., 724., 698., 960., 482., 992., 885., 663.,\n",
      "         824., 845., 709., 515., 552., 788., 931., 685.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "torch.Size([5, 20])\n",
      "tensor([[ 52., 727.,  52., 727.,   0.],\n",
      "        [ 95., 636.,  95., 636.,   0.],\n",
      "        [100., 927., 100., 927.,   0.],\n",
      "        [ 63., 421.,  63., 421.,   0.],\n",
      "        [ 96., 932.,  96., 932.,   0.],\n",
      "        [ 63., 724.,  63., 724.,   0.],\n",
      "        [ 50., 698.,  50., 698.,   0.],\n",
      "        [ 60., 960.,  60., 960.,   0.],\n",
      "        [ 60., 482.,  60., 482.,   0.],\n",
      "        [ 58., 992.,  58., 992.,   0.],\n",
      "        [ 97., 885.,  97., 885.,   0.],\n",
      "        [ 73., 663.,  73., 663.,   0.],\n",
      "        [ 58., 824.,  58., 824.,   0.],\n",
      "        [ 63., 845.,  63., 845.,   0.],\n",
      "        [ 80., 709.,  80., 709.,   0.],\n",
      "        [ 54., 515.,  54., 515.,   0.],\n",
      "        [ 51., 552.,  51., 552.,   0.],\n",
      "        [ 80., 788.,  80., 788.,   0.],\n",
      "        [ 52., 931.,  52., 931.,   0.],\n",
      "        [ 83., 685.,  83., 685.,   0.]])\n",
      "torch.Size([20, 5])\n"
     ]
    }
   ],
   "source": [
    "substrate_features = torch.tensor(substrate_features)\n",
    "print(substrate_features)\n",
    "print(substrate_features.shape)\n",
    "\n",
    "# transpose: 转置\n",
    "substrate_features = torch.transpose(substrate_features, 0, 1)\n",
    "print(substrate_features)\n",
    "print(substrate_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "streaming-overview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "tensor([  56.,  586.,   56.,  586.,    0.,   73.,  621.,   73.,  621.,    0.,\n",
      "         100.,  823.,  100.,  823.,    0.,   92.,  413.,   92.,  413.,    0.,\n",
      "          88.,  892.,   88.,  892.,    0.,   97., 1170.,   97., 1170.,    0.,\n",
      "          58.,  960.,   58.,  960.,    0.,   56.,  816.,   56.,  816.,    0.,\n",
      "          87.,  704.,   87.,  704.,    0.,   53.,  780.,   53.,  780.,    0.,\n",
      "          83.,  638.,   83.,  638.,    0.,   81.,  744.,   81.,  744.,    0.,\n",
      "          85.,  546.,   85.,  546.,    0.,   77.,  823.,   77.,  823.,    0.,\n",
      "          61.,  872.,   61.,  872.,    0.,   86.,  582.,   86.,  582.,    0.,\n",
      "          96.,  857.,   96.,  857.,    0.,   97.,  612.,   97.,  612.,    0.,\n",
      "          85.,  851.,   85.,  851.,    0.,   84., 1030.,   84., 1030.,    0.])\n"
     ]
    }
   ],
   "source": [
    "# substrate_features = torch.reshape(substrate_features, (-1,))\n",
    "# print(substrate_features.shape)\n",
    "# print(substrate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sweet-bangkok",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([103])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vnr_cpu = torch.tensor([10])\n",
    "# vnr_bw = torch.tensor([30])\n",
    "# pending = torch.tensor([2])\n",
    "# substrate_features = torch.cat((substrate_features, vnr_cpu, vnr_bw, pending), 0)\n",
    "\n",
    "# substrate_features\n",
    "# substrate_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "considered-literacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 52., 727.,  52., 727.,   0.],\n",
      "        [ 95., 636.,  95., 636.,   0.],\n",
      "        [100., 927., 100., 927.,   0.],\n",
      "        [ 63., 421.,  63., 421.,   0.],\n",
      "        [ 96., 932.,  96., 932.,   0.],\n",
      "        [ 63., 724.,  63., 724.,   0.],\n",
      "        [ 50., 698.,  50., 698.,   0.],\n",
      "        [ 60., 960.,  60., 960.,   0.],\n",
      "        [ 60., 482.,  60., 482.,   0.],\n",
      "        [ 58., 992.,  58., 992.,   0.],\n",
      "        [ 97., 885.,  97., 885.,   0.],\n",
      "        [ 73., 663.,  73., 663.,   0.],\n",
      "        [ 58., 824.,  58., 824.,   0.],\n",
      "        [ 63., 845.,  63., 845.,   0.],\n",
      "        [ 80., 709.,  80., 709.,   0.],\n",
      "        [ 54., 515.,  54., 515.,   0.],\n",
      "        [ 51., 552.,  51., 552.,   0.],\n",
      "        [ 80., 788.,  80., 788.,   0.],\n",
      "        [ 52., 931.,  52., 931.,   0.],\n",
      "        [ 83., 685.,  83., 685.,   0.]])\n"
     ]
    }
   ],
   "source": [
    "print(substrate_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-brick",
   "metadata": {},
   "source": [
    "- Using 'from_networkx'\n",
    "    - transfer the torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "capital-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = from_networkx(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "needed-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(CPU=[20], LOCATION=[20], bandwidth=[200], edge_index=[2, 200])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-relief",
   "metadata": {},
   "source": [
    "### Graph Convolution Network\n",
    "- Generate the GCN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "better-awareness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(5, 4)\n",
      "  (conv2): GCNConv(4, 4)\n",
      "  (conv3): GCNConv(4, 1)\n",
      "  (classifier): Linear(in_features=1, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        # in_channels: 节点特征数   out_channels: 输出的节点分类数\n",
    "        self.conv1 = GCNConv(in_channels=5, out_channels=4)\n",
    "        self.conv2 = GCNConv(in_channels=4, out_channels=4)\n",
    "        self.conv3 = GCNConv(in_channels=4, out_channels=1)\n",
    "        self.classifier = Linear(1, 20)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h\n",
    "\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "liberal-student",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5]) torch.Size([2, 200])\n",
      "tensor([[ 52., 727.,  52., 727.,   0.],\n",
      "        [ 95., 636.,  95., 636.,   0.],\n",
      "        [100., 927., 100., 927.,   0.],\n",
      "        [ 63., 421.,  63., 421.,   0.],\n",
      "        [ 96., 932.,  96., 932.,   0.],\n",
      "        [ 63., 724.,  63., 724.,   0.],\n",
      "        [ 50., 698.,  50., 698.,   0.],\n",
      "        [ 60., 960.,  60., 960.,   0.],\n",
      "        [ 60., 482.,  60., 482.,   0.],\n",
      "        [ 58., 992.,  58., 992.,   0.],\n",
      "        [ 97., 885.,  97., 885.,   0.],\n",
      "        [ 73., 663.,  73., 663.,   0.],\n",
      "        [ 58., 824.,  58., 824.,   0.],\n",
      "        [ 63., 845.,  63., 845.,   0.],\n",
      "        [ 80., 709.,  80., 709.,   0.],\n",
      "        [ 54., 515.,  54., 515.,   0.],\n",
      "        [ 51., 552.,  51., 552.,   0.],\n",
      "        [ 80., 788.,  80., 788.,   0.],\n",
      "        [ 52., 931.,  52., 931.,   0.],\n",
      "        [ 83., 685.,  83., 685.,   0.]])\n",
      "Embedding shape: [20, 1]\n"
     ]
    }
   ],
   "source": [
    "model = GCN()\n",
    "\n",
    "print(substrate_features.shape, data.edge_index.shape)\n",
    "print(substrate_features)\n",
    "\n",
    "out, embedding = model(substrate_features, data.edge_index)\n",
    "# out, embedding = model(data.x, data.edge_index)\n",
    "print(f'Embedding shape: {list(embedding.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "indoor-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9209],\n",
      "        [0.8982],\n",
      "        [0.9205],\n",
      "        [0.8444],\n",
      "        [0.9381],\n",
      "        [0.8986],\n",
      "        [0.9124],\n",
      "        [0.9377],\n",
      "        [0.8682],\n",
      "        [0.9381],\n",
      "        [0.9202],\n",
      "        [0.8987],\n",
      "        [0.9236],\n",
      "        [0.9322],\n",
      "        [0.9102],\n",
      "        [0.8654],\n",
      "        [0.8890],\n",
      "        [0.9067],\n",
      "        [0.9201],\n",
      "        [0.8939]], grad_fn=<TanhBackward0>)\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "print(embedding)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "expressed-ottawa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20])\n",
      "tensor([[ 0.6984, -0.1664,  1.0992,  0.2334,  0.0841, -0.7660, -0.6426,  0.2313,\n",
      "          0.8649,  0.2041,  0.9959,  0.2864,  0.2800,  0.1531, -0.8035,  1.3454,\n",
      "         -0.8052,  1.2415,  0.3402, -1.1153],\n",
      "        [ 0.6996, -0.1617,  1.0916,  0.2430,  0.0748, -0.7520, -0.6358,  0.2139,\n",
      "          0.8627,  0.2221,  0.9823,  0.3015,  0.2814,  0.1532, -0.7935,  1.3352,\n",
      "         -0.8030,  1.2291,  0.3286, -1.0975],\n",
      "        [ 0.6984, -0.1663,  1.0991,  0.2335,  0.0840, -0.7658, -0.6425,  0.2311,\n",
      "          0.8649,  0.2044,  0.9957,  0.2866,  0.2800,  0.1531, -0.8034,  1.3452,\n",
      "         -0.8052,  1.2413,  0.3400, -1.1150],\n",
      "        [ 0.7024, -0.1505,  1.0735,  0.2657,  0.0527, -0.7188, -0.6196,  0.1728,\n",
      "          0.8574,  0.2646,  0.9500,  0.3372,  0.2849,  0.1533, -0.7698,  1.3111,\n",
      "         -0.7976,  1.1997,  0.3013, -1.0555],\n",
      "        [ 0.6975, -0.1700,  1.1050,  0.2261,  0.0912, -0.7766, -0.6478,  0.2445,\n",
      "          0.8666,  0.1905,  1.0062,  0.2750,  0.2789,  0.1530, -0.8111,  1.3531,\n",
      "         -0.8069,  1.2509,  0.3489, -1.1287],\n",
      "        [ 0.6995, -0.1618,  1.0917,  0.2428,  0.0750, -0.7523, -0.6359,  0.2143,\n",
      "          0.8627,  0.2217,  0.9825,  0.3012,  0.2814,  0.1532, -0.7937,  1.3354,\n",
      "         -0.8030,  1.2293,  0.3289, -1.0979],\n",
      "        [ 0.6988, -0.1646,  1.0964,  0.2370,  0.0807, -0.7608, -0.6401,  0.2248,\n",
      "          0.8641,  0.2108,  0.9908,  0.2920,  0.2805,  0.1531, -0.7998,  1.3416,\n",
      "         -0.8044,  1.2369,  0.3359, -1.1087],\n",
      "        [ 0.6975, -0.1699,  1.1049,  0.2263,  0.0910, -0.7764, -0.6477,  0.2442,\n",
      "          0.8666,  0.1908,  1.0060,  0.2752,  0.2789,  0.1530, -0.8109,  1.3529,\n",
      "         -0.8069,  1.2507,  0.3487, -1.1284],\n",
      "        [ 0.7011, -0.1554,  1.0815,  0.2556,  0.0625, -0.7335, -0.6268,  0.1910,\n",
      "          0.8597,  0.2458,  0.9643,  0.3214,  0.2834,  0.1532, -0.7803,  1.3218,\n",
      "         -0.8000,  1.2127,  0.3134, -1.0741],\n",
      "        [ 0.6975, -0.1700,  1.1050,  0.2261,  0.0912, -0.7766, -0.6478,  0.2445,\n",
      "          0.8666,  0.1905,  1.0062,  0.2749,  0.2789,  0.1530, -0.8111,  1.3531,\n",
      "         -0.8069,  1.2509,  0.3489, -1.1287],\n",
      "        [ 0.6984, -0.1663,  1.0990,  0.2337,  0.0839, -0.7656, -0.6424,  0.2308,\n",
      "          0.8648,  0.2046,  0.9955,  0.2868,  0.2800,  0.1531, -0.8032,  1.3451,\n",
      "         -0.8051,  1.2411,  0.3399, -1.1148],\n",
      "        [ 0.6995, -0.1618,  1.0917,  0.2428,  0.0750, -0.7523, -0.6360,  0.2143,\n",
      "          0.8627,  0.2216,  0.9826,  0.3011,  0.2814,  0.1532, -0.7938,  1.3354,\n",
      "         -0.8030,  1.2294,  0.3289, -1.0979],\n",
      "        [ 0.6982, -0.1670,  1.1001,  0.2322,  0.0853, -0.7677, -0.6435,  0.2334,\n",
      "          0.8652,  0.2019,  0.9976,  0.2846,  0.2798,  0.1531, -0.8047,  1.3466,\n",
      "         -0.8055,  1.2430,  0.3416, -1.1174],\n",
      "        [ 0.6978, -0.1687,  1.1030,  0.2286,  0.0888, -0.7730, -0.6460,  0.2400,\n",
      "          0.8660,  0.1951,  1.0027,  0.2788,  0.2792,  0.1531, -0.8085,  1.3504,\n",
      "         -0.8063,  1.2477,  0.3459, -1.1241],\n",
      "        [ 0.6989, -0.1642,  1.0956,  0.2379,  0.0798, -0.7595, -0.6394,  0.2232,\n",
      "          0.8639,  0.2125,  0.9895,  0.2934,  0.2807,  0.1531, -0.7988,  1.3406,\n",
      "         -0.8042,  1.2357,  0.3348, -1.1070],\n",
      "        [ 0.7013, -0.1549,  1.0806,  0.2568,  0.0614, -0.7318, -0.6260,  0.1889,\n",
      "          0.8595,  0.2479,  0.9626,  0.3232,  0.2835,  0.1533, -0.7791,  1.3206,\n",
      "         -0.7997,  1.2112,  0.3120, -1.0719],\n",
      "        [ 0.7000, -0.1598,  1.0885,  0.2469,  0.0710, -0.7463, -0.6330,  0.2069,\n",
      "          0.8618,  0.2293,  0.9767,  0.3076,  0.2820,  0.1532, -0.7895,  1.3311,\n",
      "         -0.8021,  1.2241,  0.3240, -1.0903],\n",
      "        [ 0.6991, -0.1634,  1.0944,  0.2394,  0.0783, -0.7573, -0.6384,  0.2204,\n",
      "          0.8635,  0.2153,  0.9874,  0.2958,  0.2809,  0.1531, -0.7973,  1.3390,\n",
      "         -0.8038,  1.2337,  0.3330, -1.1042],\n",
      "        [ 0.6984, -0.1662,  1.0989,  0.2337,  0.0838, -0.7655, -0.6424,  0.2307,\n",
      "          0.8648,  0.2047,  0.9954,  0.2869,  0.2800,  0.1531, -0.8032,  1.3450,\n",
      "         -0.8051,  1.2411,  0.3398, -1.1147],\n",
      "        [ 0.6998, -0.1608,  1.0901,  0.2448,  0.0731, -0.7494, -0.6345,  0.2107,\n",
      "          0.8623,  0.2254,  0.9797,  0.3043,  0.2817,  0.1532, -0.7917,  1.3333,\n",
      "         -0.8025,  1.2268,  0.3265, -1.0942]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "672febc8a634011916ed982843df2ba95c600e4486f28df059bab71366202ec7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
