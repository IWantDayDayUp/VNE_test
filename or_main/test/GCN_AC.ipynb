{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b740024d",
   "metadata": {},
   "source": [
    "1. Actor(玩家):\n",
    "\n",
    "> 为了玩转这个游戏得到尽量高的reward, 你需要实现一个函数: 输入state, 输出action, 可以用神经网络来近似这个函数\n",
    "> \n",
    "> 剩下的任务就是如何训练神经网络, 让它的表现更好(得更高的reward)\n",
    "\n",
    "2. Critic(评委): \n",
    "\n",
    "> 为了训练actor, 你需要知道actor的表现到底怎么样, 根据表现来决定对神经网络参数的调整, 这就要用到强化学习中的“Q-value”\n",
    "> \n",
    "> 但Q-value也是一个未知的函数, 所以也可以用神经网络来近似\n",
    "\n",
    "\n",
    "Actor-Critic的训练\n",
    "\n",
    "- Actor看到游戏目前的state, 做出一个action\n",
    "\n",
    "- Critic根据state和action两者, 对actor刚才的表现打一个分数\n",
    "\n",
    "- Actor依据critic(评委)的打分, 调整自己的策略(actor神经网络参数), 争取下次做得更好\n",
    "\n",
    "- Critic根据系统给出的reward(相当于ground truth)和其他评委的打分(critic target)来调整自己的打分策略(critic神经网络参数)\n",
    "\n",
    "一开始actor随机表演, critic随机打分\n",
    "\n",
    "但是由于reward的存在, critic评分越来越准, actor表现越来越好\n",
    "\n",
    "感觉有种类似 `GAN` 的感觉, 两个网络在相互的碰撞, boom!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-cigarette",
   "metadata": {},
   "source": [
    "# GCN practice code\n",
    "\n",
    "- import basic library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d69163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda3\\envs\\test\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'torch.version' from 'e:\\\\conda3\\\\envs\\\\test\\\\lib\\\\site-packages\\\\torch\\\\version.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "existing-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from random import randint, expovariate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-spare",
   "metadata": {},
   "source": [
    "- Generate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4462929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_CPU_MAX = []\n",
    "S_BW_MAX = []\n",
    "\n",
    "# 随机生成一个图(20节点, 100链路)\n",
    "net = nx.gnm_random_graph(n=20, m=100)\n",
    "\n",
    "# 设置所有节点的CPU数据, 并同时统计最大值最小值\n",
    "min_cpu_capacity = 1.0e10\n",
    "max_cpu_capacity = 0.0\n",
    "for node_id in net.nodes:\n",
    "    net.nodes[node_id]['CPU'] = randint(50, 100)\n",
    "    net.nodes[node_id]['LOCATION'] = randint(0, 2)\n",
    "    if net.nodes[node_id]['CPU'] < min_cpu_capacity:\n",
    "        min_cpu_capacity = net.nodes[node_id]['CPU']\n",
    "    if net.nodes[node_id]['CPU'] > max_cpu_capacity:\n",
    "        max_cpu_capacity = net.nodes[node_id]['CPU']\n",
    "\n",
    "# 设置链路的带宽数据, 并同时统计最大带宽最小带宽\n",
    "min_bandwidth_capacity = 1.0e10\n",
    "max_bandwidth_capacity = 0.0\n",
    "for edge_id in net.edges:\n",
    "    net.edges[edge_id]['bandwidth'] = randint(50, 100)\n",
    "    if net.edges[edge_id]['bandwidth'] < min_bandwidth_capacity:\n",
    "        min_bandwidth_capacity = net.edges[edge_id]['bandwidth']\n",
    "    if net.edges[edge_id]['bandwidth'] > max_bandwidth_capacity:\n",
    "        max_bandwidth_capacity = net.edges[edge_id]['bandwidth']\n",
    "\n",
    "# data=True: 返回的是 NodeDataView 对象, 该对象不仅包含每个顶点的 ID 属性, 还包括顶点的其他属性\n",
    "for s_node_id, s_node_data in net.nodes(data=True):\n",
    "    S_CPU_MAX.append(s_node_data['CPU'])\n",
    "\n",
    "# 统计每个底层节点周围链路带宽和\n",
    "for s_node_id in range(len(net.nodes)):\n",
    "    total_node_bandwidth = 0.0\n",
    "    for link_id in net[s_node_id]:\n",
    "        total_node_bandwidth += net[s_node_id][link_id]['bandwidth']\n",
    "    S_BW_MAX.append(total_node_bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promotional-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    " # S_CPU_Free\n",
    "s_CPU_remaining = []\n",
    "s_bandwidth_remaining = []\n",
    "\n",
    "# 1 表示目前哪些节点被占用, 0 相反\n",
    "current_embedding = [0] * len(net.nodes)\n",
    "\n",
    "# 节点剩余资源\n",
    "for s_node_id, s_node_data in net.nodes(data=True):\n",
    "    s_CPU_remaining.append(s_node_data['CPU'])\n",
    "    \n",
    "# 节点周围剩余带宽资源\n",
    "for s_node_id in range(len(net.nodes)):\n",
    "    total_node_bandwidth = 0.0\n",
    "    for link_id in net[s_node_id]:\n",
    "        total_node_bandwidth += net[s_node_id][link_id]['bandwidth']\n",
    "    s_bandwidth_remaining.append(total_node_bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "speaking-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[95, 82, 77, 51, 78, 62, 87, 92, 66, 100, 61, 68, 52, 76, 50, 68, 57, 55, 85, 66], [856.0, 1243.0, 733.0, 587.0, 899.0, 705.0, 786.0, 556.0, 628.0, 763.0, 782.0, 763.0, 699.0, 957.0, 715.0, 960.0, 871.0, 737.0, 447.0, 1199.0], [95, 82, 77, 51, 78, 62, 87, 92, 66, 100, 61, 68, 52, 76, 50, 68, 57, 55, 85, 66], [856.0, 1243.0, 733.0, 587.0, 899.0, 705.0, 786.0, 556.0, 628.0, 763.0, 782.0, 763.0, 699.0, 957.0, 715.0, 960.0, 871.0, 737.0, 447.0, 1199.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# 底层网络特征矩阵\n",
    "substrate_features = []\n",
    "substrate_features.append(S_CPU_MAX)\n",
    "substrate_features.append(S_BW_MAX)\n",
    "substrate_features.append(s_CPU_remaining)\n",
    "substrate_features.append(s_bandwidth_remaining)\n",
    "substrate_features.append(current_embedding)\n",
    "\n",
    "print(substrate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "voluntary-favorite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  95.,   82.,   77.,   51.,   78.,   62.,   87.,   92.,   66.,  100.,\n",
      "           61.,   68.,   52.,   76.,   50.,   68.,   57.,   55.,   85.,   66.],\n",
      "        [ 856., 1243.,  733.,  587.,  899.,  705.,  786.,  556.,  628.,  763.,\n",
      "          782.,  763.,  699.,  957.,  715.,  960.,  871.,  737.,  447., 1199.],\n",
      "        [  95.,   82.,   77.,   51.,   78.,   62.,   87.,   92.,   66.,  100.,\n",
      "           61.,   68.,   52.,   76.,   50.,   68.,   57.,   55.,   85.,   66.],\n",
      "        [ 856., 1243.,  733.,  587.,  899.,  705.,  786.,  556.,  628.,  763.,\n",
      "          782.,  763.,  699.,  957.,  715.,  960.,  871.,  737.,  447., 1199.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])\n",
      "torch.Size([5, 20])\n",
      "tensor([[  95.,  856.,   95.,  856.,    0.],\n",
      "        [  82., 1243.,   82., 1243.,    0.],\n",
      "        [  77.,  733.,   77.,  733.,    0.],\n",
      "        [  51.,  587.,   51.,  587.,    0.],\n",
      "        [  78.,  899.,   78.,  899.,    0.],\n",
      "        [  62.,  705.,   62.,  705.,    0.],\n",
      "        [  87.,  786.,   87.,  786.,    0.],\n",
      "        [  92.,  556.,   92.,  556.,    0.],\n",
      "        [  66.,  628.,   66.,  628.,    0.],\n",
      "        [ 100.,  763.,  100.,  763.,    0.],\n",
      "        [  61.,  782.,   61.,  782.,    0.],\n",
      "        [  68.,  763.,   68.,  763.,    0.],\n",
      "        [  52.,  699.,   52.,  699.,    0.],\n",
      "        [  76.,  957.,   76.,  957.,    0.],\n",
      "        [  50.,  715.,   50.,  715.,    0.],\n",
      "        [  68.,  960.,   68.,  960.,    0.],\n",
      "        [  57.,  871.,   57.,  871.,    0.],\n",
      "        [  55.,  737.,   55.,  737.,    0.],\n",
      "        [  85.,  447.,   85.,  447.,    0.],\n",
      "        [  66., 1199.,   66., 1199.,    0.]])\n",
      "torch.Size([20, 5])\n"
     ]
    }
   ],
   "source": [
    "substrate_features = torch.tensor(substrate_features)\n",
    "print(substrate_features)\n",
    "print(substrate_features.shape)\n",
    "\n",
    "# transpose: 转置\n",
    "substrate_features = torch.transpose(substrate_features, 0, 1)\n",
    "print(substrate_features)\n",
    "print(substrate_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "streaming-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# substrate_features = torch.reshape(substrate_features, (-1,))\n",
    "# print(substrate_features.shape)\n",
    "# print(substrate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sweet-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vnr_cpu = torch.tensor([10])\n",
    "# vnr_bw = torch.tensor([30])\n",
    "# pending = torch.tensor([2])\n",
    "# substrate_features = torch.cat((substrate_features, vnr_cpu, vnr_bw, pending), 0)\n",
    "\n",
    "# substrate_features\n",
    "# substrate_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "considered-literacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  95.,  856.,   95.,  856.,    0.],\n",
      "        [  82., 1243.,   82., 1243.,    0.],\n",
      "        [  77.,  733.,   77.,  733.,    0.],\n",
      "        [  51.,  587.,   51.,  587.,    0.],\n",
      "        [  78.,  899.,   78.,  899.,    0.],\n",
      "        [  62.,  705.,   62.,  705.,    0.],\n",
      "        [  87.,  786.,   87.,  786.,    0.],\n",
      "        [  92.,  556.,   92.,  556.,    0.],\n",
      "        [  66.,  628.,   66.,  628.,    0.],\n",
      "        [ 100.,  763.,  100.,  763.,    0.],\n",
      "        [  61.,  782.,   61.,  782.,    0.],\n",
      "        [  68.,  763.,   68.,  763.,    0.],\n",
      "        [  52.,  699.,   52.,  699.,    0.],\n",
      "        [  76.,  957.,   76.,  957.,    0.],\n",
      "        [  50.,  715.,   50.,  715.,    0.],\n",
      "        [  68.,  960.,   68.,  960.,    0.],\n",
      "        [  57.,  871.,   57.,  871.,    0.],\n",
      "        [  55.,  737.,   55.,  737.,    0.],\n",
      "        [  85.,  447.,   85.,  447.,    0.],\n",
      "        [  66., 1199.,   66., 1199.,    0.]])\n"
     ]
    }
   ],
   "source": [
    "print(substrate_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-brick",
   "metadata": {},
   "source": [
    "- Using 'from_networkx'\n",
    "    - transfer the torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "capital-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = from_networkx(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "needed-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 200], CPU=[20], LOCATION=[20], bandwidth=[200], num_nodes=20)\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-relief",
   "metadata": {},
   "source": [
    "### Graph Convolution Network\n",
    "- Generate the GCN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "better-awareness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(5, 4)\n",
      "  (conv2): GCNConv(4, 4)\n",
      "  (conv3): GCNConv(4, 1)\n",
      "  (classifier): Linear(in_features=1, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        # in_channels: 节点特征数   out_channels: 输出的节点分类数\n",
    "        self.conv1 = GCNConv(in_channels=5, out_channels=4)\n",
    "        self.conv2 = GCNConv(in_channels=4, out_channels=4)\n",
    "        self.conv3 = GCNConv(in_channels=4, out_channels=1)\n",
    "        self.classifier = Linear(1, 20)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h\n",
    "\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "liberal-student",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5]) torch.Size([2, 200])\n",
      "tensor([[  95.,  856.,   95.,  856.,    0.],\n",
      "        [  82., 1243.,   82., 1243.,    0.],\n",
      "        [  77.,  733.,   77.,  733.,    0.],\n",
      "        [  51.,  587.,   51.,  587.,    0.],\n",
      "        [  78.,  899.,   78.,  899.,    0.],\n",
      "        [  62.,  705.,   62.,  705.,    0.],\n",
      "        [  87.,  786.,   87.,  786.,    0.],\n",
      "        [  92.,  556.,   92.,  556.,    0.],\n",
      "        [  66.,  628.,   66.,  628.,    0.],\n",
      "        [ 100.,  763.,  100.,  763.,    0.],\n",
      "        [  61.,  782.,   61.,  782.,    0.],\n",
      "        [  68.,  763.,   68.,  763.,    0.],\n",
      "        [  52.,  699.,   52.,  699.,    0.],\n",
      "        [  76.,  957.,   76.,  957.,    0.],\n",
      "        [  50.,  715.,   50.,  715.,    0.],\n",
      "        [  68.,  960.,   68.,  960.,    0.],\n",
      "        [  57.,  871.,   57.,  871.,    0.],\n",
      "        [  55.,  737.,   55.,  737.,    0.],\n",
      "        [  85.,  447.,   85.,  447.,    0.],\n",
      "        [  66., 1199.,   66., 1199.,    0.]])\n",
      "Embedding shape: [20, 1]\n"
     ]
    }
   ],
   "source": [
    "model = GCN()\n",
    "\n",
    "print(substrate_features.shape, data.edge_index.shape)\n",
    "print(substrate_features)\n",
    "\n",
    "out, embedding = model(substrate_features, data.edge_index)\n",
    "# out, embedding = model(data.x, data.edge_index)\n",
    "print(f'Embedding shape: {list(embedding.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "indoor-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7550],\n",
      "        [0.8366],\n",
      "        [0.7595],\n",
      "        [0.6825],\n",
      "        [0.7760],\n",
      "        [0.7318],\n",
      "        [0.7655],\n",
      "        [0.6840],\n",
      "        [0.7156],\n",
      "        [0.7574],\n",
      "        [0.7429],\n",
      "        [0.7295],\n",
      "        [0.7424],\n",
      "        [0.7824],\n",
      "        [0.7400],\n",
      "        [0.8235],\n",
      "        [0.7747],\n",
      "        [0.7684],\n",
      "        [0.6608],\n",
      "        [0.8380]], grad_fn=<TanhBackward0>)\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "print(embedding)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expressed-ottawa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20])\n",
      "tensor([[-0.9013,  0.0658,  0.2151, -0.8476,  0.4945, -1.5472,  0.3259, -0.5638,\n",
      "         -1.6169, -0.0826, -0.5106, -0.9745,  0.1948,  0.6400,  0.3509, -0.2696,\n",
      "         -0.3130, -0.4192, -0.3950,  0.6328],\n",
      "        [-0.9017,  0.1159,  0.1428, -0.9109,  0.4796, -1.6282,  0.3370, -0.6216,\n",
      "         -1.6902, -0.1157, -0.5544, -0.9749,  0.2495,  0.6201,  0.3672, -0.2327,\n",
      "         -0.2910, -0.4151, -0.3817,  0.6808],\n",
      "        [-0.9013,  0.0685,  0.2111, -0.8511,  0.4937, -1.5517,  0.3265, -0.5670,\n",
      "         -1.6210, -0.0844, -0.5130, -0.9745,  0.1978,  0.6389,  0.3518, -0.2676,\n",
      "         -0.3118, -0.4189, -0.3943,  0.6354],\n",
      "        [-0.9009,  0.0212,  0.2794, -0.7914,  0.5078, -1.4754,  0.3161, -0.5125,\n",
      "         -1.5518, -0.0531, -0.4718, -0.9741,  0.1462,  0.6577,  0.3365, -0.3024,\n",
      "         -0.3325, -0.4227, -0.4069,  0.5901],\n",
      "        [-0.9014,  0.0787,  0.1965, -0.8639,  0.4907, -1.5681,  0.3288, -0.5787,\n",
      "         -1.6358, -0.0911, -0.5219, -0.9746,  0.2089,  0.6349,  0.3551, -0.2601,\n",
      "         -0.3073, -0.4181, -0.3916,  0.6451],\n",
      "        [-0.9012,  0.0515,  0.2357, -0.8296,  0.4988, -1.5242,  0.3228, -0.5474,\n",
      "         -1.5961, -0.0731, -0.4982, -0.9744,  0.1793,  0.6457,  0.3463, -0.2801,\n",
      "         -0.3192, -0.4203, -0.3988,  0.6191],\n",
      "        [-0.9013,  0.0722,  0.2059, -0.8557,  0.4926, -1.5576,  0.3273, -0.5712,\n",
      "         -1.6263, -0.0868, -0.5162, -0.9745,  0.2018,  0.6375,  0.3530, -0.2649,\n",
      "         -0.3102, -0.4186, -0.3933,  0.6389],\n",
      "        [-0.9009,  0.0221,  0.2780, -0.7926,  0.5075, -1.4768,  0.3163, -0.5135,\n",
      "         -1.5532, -0.0537, -0.4726, -0.9741,  0.1472,  0.6573,  0.3368, -0.3017,\n",
      "         -0.3321, -0.4227, -0.4066,  0.5909],\n",
      "        [-0.9011,  0.0416,  0.2500, -0.8171,  0.5017, -1.5082,  0.3206, -0.5359,\n",
      "         -1.5816, -0.0666, -0.4895, -0.9743,  0.1684,  0.6496,  0.3431, -0.2874,\n",
      "         -0.3236, -0.4211, -0.4015,  0.6096],\n",
      "        [-0.9013,  0.0673,  0.2130, -0.8495,  0.4941, -1.5496,  0.3262, -0.5655,\n",
      "         -1.6191, -0.0836, -0.5119, -0.9745,  0.1965,  0.6394,  0.3514, -0.2685,\n",
      "         -0.3123, -0.4190, -0.3947,  0.6342],\n",
      "        [-0.9012,  0.0583,  0.2259, -0.8382,  0.4968, -1.5352,  0.3243, -0.5552,\n",
      "         -1.6060, -0.0777, -0.5041, -0.9744,  0.1867,  0.6430,  0.3485, -0.2751,\n",
      "         -0.3162, -0.4198, -0.3970,  0.6256],\n",
      "        [-0.9012,  0.0501,  0.2377, -0.8279,  0.4992, -1.5220,  0.3225, -0.5458,\n",
      "         -1.5940, -0.0722, -0.4970, -0.9744,  0.1778,  0.6462,  0.3458, -0.2811,\n",
      "         -0.3198, -0.4204, -0.3992,  0.6177],\n",
      "        [-0.9012,  0.0580,  0.2263, -0.8378,  0.4969, -1.5347,  0.3242, -0.5548,\n",
      "         -1.6056, -0.0774, -0.5038, -0.9744,  0.1864,  0.6431,  0.3484, -0.2753,\n",
      "         -0.3164, -0.4198, -0.3971,  0.6253],\n",
      "        [-0.9014,  0.0826,  0.1909, -0.8688,  0.4895, -1.5743,  0.3296, -0.5832,\n",
      "         -1.6415, -0.0937, -0.5253, -0.9746,  0.2132,  0.6334,  0.3564, -0.2572,\n",
      "         -0.3056, -0.4178, -0.3906,  0.6489],\n",
      "        [-0.9012,  0.0566,  0.2284, -0.8360,  0.4973, -1.5324,  0.3239, -0.5532,\n",
      "         -1.6035, -0.0765, -0.5026, -0.9744,  0.1848,  0.6437,  0.3479, -0.2764,\n",
      "         -0.3170, -0.4199, -0.3975,  0.6239],\n",
      "        [-0.9016,  0.1079,  0.1544, -0.9007,  0.4820, -1.6151,  0.3352, -0.6123,\n",
      "         -1.6784, -0.1104, -0.5473, -0.9748,  0.2408,  0.6233,  0.3646, -0.2386,\n",
      "         -0.2945, -0.4158, -0.3839,  0.6731],\n",
      "        [-0.9014,  0.0779,  0.1977, -0.8629,  0.4909, -1.5667,  0.3286, -0.5777,\n",
      "         -1.6346, -0.0906, -0.5212, -0.9746,  0.2080,  0.6352,  0.3548, -0.2607,\n",
      "         -0.3077, -0.4182, -0.3918,  0.6443],\n",
      "        [-0.9013,  0.0740,  0.2033, -0.8580,  0.4921, -1.5605,  0.3277, -0.5733,\n",
      "         -1.6289, -0.0880, -0.5178, -0.9746,  0.2038,  0.6368,  0.3536, -0.2636,\n",
      "         -0.3094, -0.4185, -0.3929,  0.6406],\n",
      "        [-0.9008,  0.0078,  0.2986, -0.7746,  0.5118, -1.4538,  0.3131, -0.4971,\n",
      "         -1.5323, -0.0443, -0.4601, -0.9740,  0.1317,  0.6630,  0.3322, -0.3122,\n",
      "         -0.3383, -0.4238, -0.4104,  0.5773],\n",
      "        [-0.9017,  0.1168,  0.1416, -0.9119,  0.4794, -1.6295,  0.3372, -0.6226,\n",
      "         -1.6914, -0.1163, -0.5551, -0.9749,  0.2504,  0.6198,  0.3674, -0.2321,\n",
      "         -0.2907, -0.4151, -0.3815,  0.6816]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "672febc8a634011916ed982843df2ba95c600e4486f28df059bab71366202ec7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
