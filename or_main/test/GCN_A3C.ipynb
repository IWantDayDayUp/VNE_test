{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "third-cigarette",
   "metadata": {},
   "source": [
    "# GCN practice code\n",
    "\n",
    "- import basic library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d69163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.version' from 'e:\\\\conda3\\\\envs\\\\test\\\\lib\\\\site-packages\\\\torch\\\\version.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "existing-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from random import randint, expovariate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-spare",
   "metadata": {},
   "source": [
    "- Generate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4462929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_CPU_MAX = []\n",
    "S_BW_MAX = []\n",
    "\n",
    "# 随机生成一个图(20节点, 100链路)\n",
    "net = nx.gnm_random_graph(n=20, m=100)\n",
    "\n",
    "# 设置所有节点的CPU数据, 并同时统计最大值最小值\n",
    "min_cpu_capacity = 1.0e10\n",
    "max_cpu_capacity = 0.0\n",
    "for node_id in net.nodes:\n",
    "    net.nodes[node_id]['CPU'] = randint(50, 100)\n",
    "    net.nodes[node_id]['LOCATION'] = randint(0, 2)\n",
    "    \n",
    "    if net.nodes[node_id]['CPU'] < min_cpu_capacity:\n",
    "        min_cpu_capacity = net.nodes[node_id]['CPU']\n",
    "    if net.nodes[node_id]['CPU'] > max_cpu_capacity:\n",
    "        max_cpu_capacity = net.nodes[node_id]['CPU']\n",
    "\n",
    "# 设置链路的带宽数据, 并同时统计最大带宽最小带宽\n",
    "min_bandwidth_capacity = 1.0e10\n",
    "max_bandwidth_capacity = 0.0\n",
    "for edge_id in net.edges:\n",
    "    net.edges[edge_id]['bandwidth'] = randint(50, 100)\n",
    "    \n",
    "    if net.edges[edge_id]['bandwidth'] < min_bandwidth_capacity:\n",
    "        min_bandwidth_capacity = net.edges[edge_id]['bandwidth']\n",
    "    if net.edges[edge_id]['bandwidth'] > max_bandwidth_capacity:\n",
    "        max_bandwidth_capacity = net.edges[edge_id]['bandwidth']\n",
    "\n",
    "# data=True: 返回的是 NodeDataView 对象, 该对象不仅包含每个顶点的 ID 属性, 还包括顶点的其他属性\n",
    "for s_node_id, s_node_data in net.nodes(data=True):\n",
    "    S_CPU_MAX.append(s_node_data['CPU'])\n",
    "\n",
    "# 统计每个底层节点周围链路带宽和\n",
    "for s_node_id in range(len(net.nodes)):\n",
    "    total_node_bandwidth = 0.0\n",
    "    for link_id in net[s_node_id]:\n",
    "        total_node_bandwidth += net[s_node_id][link_id]['bandwidth']\n",
    "    S_BW_MAX.append(total_node_bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promotional-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    " # S_CPU_Free\n",
    "s_CPU_remaining = []\n",
    "s_bandwidth_remaining = []\n",
    "\n",
    "# 1 表示目前哪些节点被占用, 0 相反\n",
    "current_embedding = [0] * len(net.nodes)\n",
    "\n",
    "# 节点剩余资源\n",
    "for s_node_id, s_node_data in net.nodes(data=True):\n",
    "    s_CPU_remaining.append(s_node_data['CPU'])\n",
    "    \n",
    "# 节点周围剩余带宽资源\n",
    "for s_node_id in range(len(net.nodes)):\n",
    "    total_node_bandwidth = 0.0\n",
    "    for link_id in net[s_node_id]:\n",
    "        total_node_bandwidth += net[s_node_id][link_id]['bandwidth']\n",
    "    s_bandwidth_remaining.append(total_node_bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "speaking-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74, 63, 78, 68, 90, 60, 95, 85, 72, 99, 51, 67, 58, 61, 69, 54, 71, 69, 88, 88], [720.0, 869.0, 933.0, 922.0, 823.0, 589.0, 689.0, 768.0, 577.0, 581.0, 723.0, 787.0, 970.0, 553.0, 828.0, 649.0, 608.0, 567.0, 743.0, 891.0], [74, 63, 78, 68, 90, 60, 95, 85, 72, 99, 51, 67, 58, 61, 69, 54, 71, 69, 88, 88], [720.0, 869.0, 933.0, 922.0, 823.0, 589.0, 689.0, 768.0, 577.0, 581.0, 723.0, 787.0, 970.0, 553.0, 828.0, 649.0, 608.0, 567.0, 743.0, 891.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# 底层网络特征矩阵\n",
    "substrate_features = []\n",
    "substrate_features.append(S_CPU_MAX)\n",
    "substrate_features.append(S_BW_MAX)\n",
    "substrate_features.append(s_CPU_remaining)\n",
    "substrate_features.append(s_bandwidth_remaining)\n",
    "substrate_features.append(current_embedding)\n",
    "\n",
    "print(substrate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "voluntary-favorite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 74.,  63.,  78.,  68.,  90.,  60.,  95.,  85.,  72.,  99.,  51.,  67.,\n",
      "          58.,  61.,  69.,  54.,  71.,  69.,  88.,  88.],\n",
      "        [720., 869., 933., 922., 823., 589., 689., 768., 577., 581., 723., 787.,\n",
      "         970., 553., 828., 649., 608., 567., 743., 891.],\n",
      "        [ 74.,  63.,  78.,  68.,  90.,  60.,  95.,  85.,  72.,  99.,  51.,  67.,\n",
      "          58.,  61.,  69.,  54.,  71.,  69.,  88.,  88.],\n",
      "        [720., 869., 933., 922., 823., 589., 689., 768., 577., 581., 723., 787.,\n",
      "         970., 553., 828., 649., 608., 567., 743., 891.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "torch.Size([5, 20])\n",
      "tensor([[ 74., 720.,  74., 720.,   0.],\n",
      "        [ 63., 869.,  63., 869.,   0.],\n",
      "        [ 78., 933.,  78., 933.,   0.],\n",
      "        [ 68., 922.,  68., 922.,   0.],\n",
      "        [ 90., 823.,  90., 823.,   0.],\n",
      "        [ 60., 589.,  60., 589.,   0.],\n",
      "        [ 95., 689.,  95., 689.,   0.],\n",
      "        [ 85., 768.,  85., 768.,   0.],\n",
      "        [ 72., 577.,  72., 577.,   0.],\n",
      "        [ 99., 581.,  99., 581.,   0.],\n",
      "        [ 51., 723.,  51., 723.,   0.],\n",
      "        [ 67., 787.,  67., 787.,   0.],\n",
      "        [ 58., 970.,  58., 970.,   0.],\n",
      "        [ 61., 553.,  61., 553.,   0.],\n",
      "        [ 69., 828.,  69., 828.,   0.],\n",
      "        [ 54., 649.,  54., 649.,   0.],\n",
      "        [ 71., 608.,  71., 608.,   0.],\n",
      "        [ 69., 567.,  69., 567.,   0.],\n",
      "        [ 88., 743.,  88., 743.,   0.],\n",
      "        [ 88., 891.,  88., 891.,   0.]])\n",
      "torch.Size([20, 5])\n"
     ]
    }
   ],
   "source": [
    "substrate_features = torch.tensor(substrate_features)\n",
    "print(substrate_features)\n",
    "print(substrate_features.shape)\n",
    "\n",
    "# transpose: 转置\n",
    "substrate_features = torch.transpose(substrate_features, 0, 1)\n",
    "print(substrate_features)\n",
    "print(substrate_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "streaming-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# substrate_features = torch.reshape(substrate_features, (-1,))\n",
    "# print(substrate_features.shape)\n",
    "# print(substrate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sweet-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vnr_cpu = torch.tensor([10])\n",
    "# vnr_bw = torch.tensor([30])\n",
    "# pending = torch.tensor([2])\n",
    "# substrate_features = torch.cat((substrate_features, vnr_cpu, vnr_bw, pending), 0)\n",
    "\n",
    "# substrate_features\n",
    "# substrate_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "considered-literacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 74., 720.,  74., 720.,   0.],\n",
      "        [ 63., 869.,  63., 869.,   0.],\n",
      "        [ 78., 933.,  78., 933.,   0.],\n",
      "        [ 68., 922.,  68., 922.,   0.],\n",
      "        [ 90., 823.,  90., 823.,   0.],\n",
      "        [ 60., 589.,  60., 589.,   0.],\n",
      "        [ 95., 689.,  95., 689.,   0.],\n",
      "        [ 85., 768.,  85., 768.,   0.],\n",
      "        [ 72., 577.,  72., 577.,   0.],\n",
      "        [ 99., 581.,  99., 581.,   0.],\n",
      "        [ 51., 723.,  51., 723.,   0.],\n",
      "        [ 67., 787.,  67., 787.,   0.],\n",
      "        [ 58., 970.,  58., 970.,   0.],\n",
      "        [ 61., 553.,  61., 553.,   0.],\n",
      "        [ 69., 828.,  69., 828.,   0.],\n",
      "        [ 54., 649.,  54., 649.,   0.],\n",
      "        [ 71., 608.,  71., 608.,   0.],\n",
      "        [ 69., 567.,  69., 567.,   0.],\n",
      "        [ 88., 743.,  88., 743.,   0.],\n",
      "        [ 88., 891.,  88., 891.,   0.]])\n"
     ]
    }
   ],
   "source": [
    "print(substrate_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-brick",
   "metadata": {},
   "source": [
    "- Using 'from_networkx'\n",
    "    - transfer the torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "capital-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = from_networkx(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "needed-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(CPU=[20], LOCATION=[20], bandwidth=[200], edge_index=[2, 200])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-relief",
   "metadata": {},
   "source": [
    "### Graph Convolution Network\n",
    "- Generate the GCN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "better-awareness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(5, 4)\n",
      "  (conv2): GCNConv(4, 4)\n",
      "  (conv3): GCNConv(4, 1)\n",
      "  (classifier): Linear(in_features=1, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        # in_channels: 节点特征数   out_channels: 输出的节点分类数\n",
    "        self.conv1 = GCNConv(in_channels=5, out_channels=4)\n",
    "        self.conv2 = GCNConv(in_channels=4, out_channels=4)\n",
    "        self.conv3 = GCNConv(in_channels=4, out_channels=1)\n",
    "        self.classifier = Linear(1, 20)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h\n",
    "\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "liberal-student",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5]) torch.Size([2, 200])\n",
      "tensor([[ 74., 720.,  74., 720.,   0.],\n",
      "        [ 63., 869.,  63., 869.,   0.],\n",
      "        [ 78., 933.,  78., 933.,   0.],\n",
      "        [ 68., 922.,  68., 922.,   0.],\n",
      "        [ 90., 823.,  90., 823.,   0.],\n",
      "        [ 60., 589.,  60., 589.,   0.],\n",
      "        [ 95., 689.,  95., 689.,   0.],\n",
      "        [ 85., 768.,  85., 768.,   0.],\n",
      "        [ 72., 577.,  72., 577.,   0.],\n",
      "        [ 99., 581.,  99., 581.,   0.],\n",
      "        [ 51., 723.,  51., 723.,   0.],\n",
      "        [ 67., 787.,  67., 787.,   0.],\n",
      "        [ 58., 970.,  58., 970.,   0.],\n",
      "        [ 61., 553.,  61., 553.,   0.],\n",
      "        [ 69., 828.,  69., 828.,   0.],\n",
      "        [ 54., 649.,  54., 649.,   0.],\n",
      "        [ 71., 608.,  71., 608.,   0.],\n",
      "        [ 69., 567.,  69., 567.,   0.],\n",
      "        [ 88., 743.,  88., 743.,   0.],\n",
      "        [ 88., 891.,  88., 891.,   0.]])\n",
      "Embedding shape: [20, 1]\n"
     ]
    }
   ],
   "source": [
    "model = GCN()\n",
    "\n",
    "print(substrate_features.shape, data.edge_index.shape)\n",
    "print(substrate_features)\n",
    "\n",
    "out, embedding = model(substrate_features, data.edge_index)\n",
    "# out, embedding = model(data.x, data.edge_index)\n",
    "print(f'Embedding shape: {list(embedding.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "indoor-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9108],\n",
      "        [0.9289],\n",
      "        [0.9293],\n",
      "        [0.9311],\n",
      "        [0.9205],\n",
      "        [0.8647],\n",
      "        [0.9087],\n",
      "        [0.9105],\n",
      "        [0.8877],\n",
      "        [0.8866],\n",
      "        [0.9094],\n",
      "        [0.9258],\n",
      "        [0.9394],\n",
      "        [0.8805],\n",
      "        [0.9247],\n",
      "        [0.9013],\n",
      "        [0.8805],\n",
      "        [0.8671],\n",
      "        [0.9199],\n",
      "        [0.9296]], grad_fn=<TanhBackward0>)\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "print(embedding)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expressed-ottawa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20])\n",
      "tensor([[ 0.6989, -0.1643,  1.0958,  0.2376,  0.0800, -0.7598, -0.6396,  0.2236,\n",
      "          0.8639,  0.2120,  0.9899,  0.2930,  0.2806,  0.1531, -0.7991,  1.3409,\n",
      "         -0.8042,  1.2360,  0.3351, -1.1074],\n",
      "        [ 0.6979, -0.1681,  1.1019,  0.2300,  0.0874, -0.7710, -0.6450,  0.2374,\n",
      "          0.8657,  0.1978,  1.0007,  0.2811,  0.2795,  0.1531, -0.8071,  1.3489,\n",
      "         -0.8060,  1.2459,  0.3442, -1.1215],\n",
      "        [ 0.6979, -0.1681,  1.1020,  0.2298,  0.0876, -0.7712, -0.6452,  0.2378,\n",
      "          0.8657,  0.1974,  1.0010,  0.2808,  0.2794,  0.1531, -0.8073,  1.3491,\n",
      "         -0.8060,  1.2461,  0.3445, -1.1219],\n",
      "        [ 0.6978, -0.1685,  1.1027,  0.2291,  0.0883, -0.7724, -0.6457,  0.2392,\n",
      "          0.8659,  0.1960,  1.0021,  0.2796,  0.2793,  0.1531, -0.8080,  1.3500,\n",
      "         -0.8062,  1.2471,  0.3454, -1.1233],\n",
      "        [ 0.6984, -0.1663,  1.0991,  0.2335,  0.0840, -0.7658, -0.6425,  0.2310,\n",
      "          0.8649,  0.2044,  0.9957,  0.2866,  0.2800,  0.1531, -0.8034,  1.3452,\n",
      "         -0.8052,  1.2413,  0.3400, -1.1150],\n",
      "        [ 0.7013, -0.1547,  1.0803,  0.2571,  0.0611, -0.7314, -0.6258,  0.1883,\n",
      "          0.8594,  0.2485,  0.9622,  0.3237,  0.2836,  0.1533, -0.7788,  1.3202,\n",
      "         -0.7997,  1.2108,  0.3116, -1.0714],\n",
      "        [ 0.6990, -0.1639,  1.0951,  0.2386,  0.0791, -0.7585, -0.6390,  0.2220,\n",
      "          0.8637,  0.2137,  0.9886,  0.2945,  0.2808,  0.1531, -0.7982,  1.3399,\n",
      "         -0.8040,  1.2348,  0.3340, -1.1057],\n",
      "        [ 0.6989, -0.1642,  1.0957,  0.2378,  0.0799, -0.7596, -0.6395,  0.2234,\n",
      "          0.8639,  0.2123,  0.9897,  0.2933,  0.2806,  0.1531, -0.7990,  1.3407,\n",
      "         -0.8042,  1.2359,  0.3349, -1.1072],\n",
      "        [ 0.7001, -0.1595,  1.0881,  0.2474,  0.0705, -0.7456, -0.6327,  0.2059,\n",
      "          0.8617,  0.2303,  0.9760,  0.3084,  0.2821,  0.1532, -0.7889,  1.3305,\n",
      "         -0.8019,  1.2234,  0.3233, -1.0894],\n",
      "        [ 0.7002, -0.1593,  1.0877,  0.2479,  0.0700, -0.7449, -0.6323,  0.2051,\n",
      "          0.8615,  0.2312,  0.9753,  0.3092,  0.2822,  0.1532, -0.7884,  1.3300,\n",
      "         -0.8018,  1.2228,  0.3227, -1.0885],\n",
      "        [ 0.6990, -0.1640,  1.0953,  0.2382,  0.0794, -0.7590, -0.6392,  0.2225,\n",
      "          0.8638,  0.2132,  0.9890,  0.2940,  0.2807,  0.1531, -0.7985,  1.3402,\n",
      "         -0.8041,  1.2352,  0.3344, -1.1063],\n",
      "        [ 0.6981, -0.1674,  1.1009,  0.2313,  0.0862, -0.7691, -0.6441,  0.2351,\n",
      "          0.8654,  0.2002,  0.9989,  0.2831,  0.2797,  0.1531, -0.8057,  1.3476,\n",
      "         -0.8057,  1.2442,  0.3427, -1.1191],\n",
      "        [ 0.6974, -0.1702,  1.1054,  0.2256,  0.0918, -0.7775, -0.6482,  0.2455,\n",
      "          0.8667,  0.1894,  1.0071,  0.2740,  0.2788,  0.1530, -0.8117,  1.3537,\n",
      "         -0.8070,  1.2516,  0.3496, -1.1298],\n",
      "        [ 0.7005, -0.1580,  1.0856,  0.2505,  0.0675, -0.7411, -0.6305,  0.2004,\n",
      "          0.8609,  0.2360,  0.9716,  0.3132,  0.2826,  0.1532, -0.7857,  1.3273,\n",
      "         -0.8012,  1.2194,  0.3197, -1.0837],\n",
      "        [ 0.6982, -0.1672,  1.1005,  0.2318,  0.0857, -0.7684, -0.6438,  0.2342,\n",
      "          0.8653,  0.2011,  0.9982,  0.2839,  0.2797,  0.1531, -0.8052,  1.3471,\n",
      "         -0.8056,  1.2436,  0.3421, -1.1183],\n",
      "        [ 0.6994, -0.1623,  1.0926,  0.2417,  0.0761, -0.7540, -0.6368,  0.2163,\n",
      "          0.8630,  0.2196,  0.9842,  0.2994,  0.2812,  0.1532, -0.7949,  1.3366,\n",
      "         -0.8033,  1.2308,  0.3302, -1.1000],\n",
      "        [ 0.7005, -0.1580,  1.0856,  0.2505,  0.0676, -0.7411, -0.6305,  0.2004,\n",
      "          0.8610,  0.2360,  0.9717,  0.3132,  0.2826,  0.1532, -0.7857,  1.3273,\n",
      "         -0.8012,  1.2195,  0.3197, -1.0837],\n",
      "        [ 0.7012, -0.1552,  1.0811,  0.2561,  0.0621, -0.7329, -0.6265,  0.1902,\n",
      "          0.8596,  0.2466,  0.9636,  0.3221,  0.2834,  0.1533, -0.7798,  1.3213,\n",
      "         -0.7999,  1.2121,  0.3129, -1.0732],\n",
      "        [ 0.6984, -0.1662,  1.0989,  0.2338,  0.0837, -0.7654, -0.6423,  0.2306,\n",
      "          0.8648,  0.2049,  0.9953,  0.2870,  0.2800,  0.1531, -0.8031,  1.3449,\n",
      "         -0.8051,  1.2410,  0.3397, -1.1145],\n",
      "        [ 0.6979, -0.1682,  1.1022,  0.2297,  0.0877, -0.7714, -0.6453,  0.2380,\n",
      "          0.8658,  0.1972,  1.0012,  0.2805,  0.2794,  0.1531, -0.8074,  1.3493,\n",
      "         -0.8061,  1.2463,  0.3446, -1.1221]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-chess",
   "metadata": {},
   "source": [
    "# A3C Code\n",
    "- Simple A3C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rational-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def v_wrap(np_array, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    将numpy数据转换为torch类型\n",
    "    \"\"\"\n",
    "    if np_array.dtype != dtype:\n",
    "        np_array = np_array.astype(dtype)\n",
    "    return torch.from_numpy(np_array)\n",
    "\n",
    "\n",
    "def set_init(layers):\n",
    "    \"\"\"\n",
    "    所有网络层初始化\n",
    "    \"\"\"\n",
    "    for layer in layers:\n",
    "        nn.init.normal_(layer.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(layer.bias, 0.)\n",
    "\n",
    "\n",
    "def push_and_pull(opt, lnet, gnet, done, s_, bs, buffer_action, buffer_reward, gamma):\n",
    "    \"\"\"\n",
    "    pull: 把主网络的参数直接赋予Worker中的网络\n",
    "    push: 使用各Worker中的梯度, 对主网络的参数进行更新\n",
    "    \"\"\"\n",
    "    if done:\n",
    "        v_s_ = 0.               # terminal\n",
    "    else:\n",
    "        v_s_ = lnet.forward(v_wrap(s_[None, :]))[-1].data.numpy()[0, 0]\n",
    "\n",
    "    buffer_v_target = []\n",
    "    for r in buffer_reward[::-1]:    # reverse buffer r\n",
    "        v_s_ = r + gamma * v_s_\n",
    "        buffer_v_target.append(v_s_)\n",
    "    buffer_v_target.reverse()\n",
    "    \n",
    "    \n",
    "    loss = lnet.loss_func(\n",
    "        v_wrap(np.vstack(bs)),\n",
    "        v_wrap(np.array(buffer_action), dtype=np.int64) if buffer_action[0].dtype == np.int64 else v_wrap(np.vstack(buffer_action)),\n",
    "        v_wrap(np.array(buffer_v_target)[:, None]))\n",
    "\n",
    "    # calculate local gradients and push local parameters to global\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    for lp, gp in zip(lnet.parameters(), gnet.parameters()):\n",
    "        gp._grad = lp.grad\n",
    "    opt.step()\n",
    "\n",
    "    # pull global parameters\n",
    "    lnet.load_state_dict(gnet.state_dict())\n",
    "\n",
    "\n",
    "def record(global_ep, global_ep_r, ep_r, res_queue, name):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    with global_ep.get_lock():\n",
    "        global_ep.value += 1\n",
    "        \n",
    "    with global_ep_r.get_lock():\n",
    "        if global_ep_r.value == 0.:\n",
    "            global_ep_r.value = ep_r\n",
    "        else:\n",
    "            global_ep_r.value = global_ep_r.value * 0.99 + ep_r * 0.01\n",
    "            \n",
    "    res_queue.put(global_ep_r.value)\n",
    "    \n",
    "    print(\n",
    "        name,\n",
    "        \"Ep:\", global_ep.value,\n",
    "        \"| Ep_r: %.0f\" % global_ep_r.value,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "committed-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedAdam(torch.optim.Adam):\n",
    "    \"\"\"\n",
    "    优化器\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.99), eps=1e-8,\n",
    "                 weight_decay=0):\n",
    "        super(SharedAdam, self).__init__(params, lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        \n",
    "        # State initialization\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                state['step'] = 0\n",
    "                state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "\n",
    "                # share in memory\n",
    "                state['exp_avg'].share_memory_()\n",
    "                state['exp_avg_sq'].share_memory_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "vocal-luther",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import gym\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "UPDATE_GLOBAL_ITER = 5\n",
    "GAMMA = 0.9\n",
    "MAX_EP = 3000\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "N_S = env.observation_space.shape[0]\n",
    "N_A = env.action_space.n\n",
    "\n",
    "print(N_S, N_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "surrounded-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.s_dim = s_dim\n",
    "        self.a_dim = a_dim\n",
    "        self.pi1 = nn.Linear(s_dim, 128)\n",
    "        self.pi2 = nn.Linear(128, a_dim)\n",
    "        self.v1 = nn.Linear(s_dim, 128)\n",
    "        self.v2 = nn.Linear(128, 1)\n",
    "        set_init([self.pi1, self.pi2, self.v1, self.v2])\n",
    "        self.distribution = torch.distributions.Categorical\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        \"\"\"\n",
    "        pi1 = torch.tanh(self.pi1(x))\n",
    "        logits = self.pi2(pi1)\n",
    "        v1 = torch.tanh(self.v1(x))\n",
    "        values = self.v2(v1)\n",
    "        return logits, values\n",
    "\n",
    "    def choose_action(self, s):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        # 生成每个动作的概率, 选择最大的\n",
    "        logits, _ = self.forward(s)\n",
    "        prob = F.softmax(logits, dim=1).data\n",
    "        m = self.distribution(prob)\n",
    "        \n",
    "        return m.sample().numpy()[0]\n",
    "\n",
    "    def loss_func(self, s, a, v_t):\n",
    "        \"\"\"\n",
    "        计算误差\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "        \n",
    "        logits, values = self.forward(s)\n",
    "        \n",
    "        # 误差\n",
    "        td = v_t - values\n",
    "        c_loss = td.pow(2)\n",
    "        \n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        m = self.distribution(probs)\n",
    "        exp_v = m.log_prob(a) * td.detach().squeeze()\n",
    "        a_loss = -exp_v\n",
    "        total_loss = (c_loss + a_loss).mean()\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "derived-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(mp.Process):\n",
    "    ''\n",
    "    \n",
    "    def __init__(self, gnet, opt, global_ep, global_ep_r, res_queue, name):\n",
    "        super(Worker, self).__init__()\n",
    "        self.name = 'w%02i' % name\n",
    "        self.g_ep, self.g_ep_r, self.res_queue = global_ep, global_ep_r, res_queue\n",
    "        self.gnet, self.opt = gnet, opt\n",
    "        self.lnet = Net(N_S, N_A)           # local network\n",
    "        self.env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        total_step = 1\n",
    "        while self.g_ep.value < MAX_EP:\n",
    "            # 重置环境\n",
    "            s = self.env.reset()\n",
    "            \n",
    "            # 记录\n",
    "            buffer_s, buffer_action, buffer_reward = [], [], []\n",
    "            \n",
    "            # 总收益\n",
    "            ep_r = 0.\n",
    "            \n",
    "            while True:\n",
    "#                 if self.name == 'w00':\n",
    "#                     self.env.render()\n",
    "                print(s)\n",
    "                \n",
    "                # 根据当前环境, 生成一个动作action\n",
    "                a = self.lnet.choose_action(v_wrap(s[None, :]))\n",
    "                print(s[None, :])\n",
    "                print(v_wrap(s[None, :]))\n",
    "                \n",
    "                # 执行action, 返回: 下一状态, reward, 是否结束, 其他信息\n",
    "                s_, r, done, _ = self.env.step(a)\n",
    "                if done: r = -1\n",
    "                \n",
    "                # 总收益\n",
    "                ep_r += r\n",
    "                \n",
    "                # 记录\n",
    "                buffer_action.append(a)\n",
    "                buffer_s.append(s)\n",
    "                buffer_reward.append(r)\n",
    "\n",
    "                if total_step % UPDATE_GLOBAL_ITER == 0 or done:  # update global and assign to local net\n",
    "                    # sync\n",
    "                    push_and_pull(self.opt, self.lnet, self.gnet, done, s_, buffer_s, buffer_action, buffer_reward, GAMMA)\n",
    "                    buffer_s, buffer_action, buffer_reward = [], [], []\n",
    "\n",
    "                    if done:  # done and print information\n",
    "                        record(self.g_ep, self.g_ep_r, ep_r, self.res_queue, self.name)\n",
    "                        break\n",
    "                s = s_\n",
    "                total_step += 1\n",
    "        self.res_queue.put(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sealed-observation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "gnet = Net(N_S, N_A)        # global network\n",
    "gnet.share_memory()         # share the global parameters in multiprocessing\n",
    "opt = SharedAdam(gnet.parameters(), lr=1e-4, betas=(0.92, 0.999))      # global optimizer\n",
    "\n",
    "global_ep, global_ep_r, res_queue = mp.Value('i', 0), mp.Value('d', 0.), mp.Queue()\n",
    "print(mp.cpu_count())\n",
    "\n",
    "# parallel training\n",
    "workers = [Worker(gnet, opt, global_ep, global_ep_r, res_queue, i) for i in range(mp.cpu_count())]\n",
    "[w.start() for w in workers]\n",
    "res = []                    # record episode reward to plot\n",
    "while True:\n",
    "    r = res_queue.get()\n",
    "    if r is not None:\n",
    "        res.append(r)\n",
    "    else:\n",
    "        break\n",
    "[w.join() for w in workers]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(res)\n",
    "plt.ylabel('Moving average ep reward')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "672febc8a634011916ed982843df2ba95c600e4486f28df059bab71366202ec7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
