{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "third-cigarette",
   "metadata": {},
   "source": [
    "# GCN practice code\n",
    "\n",
    "- import basic library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "34d69163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.version' from 'e:\\\\conda3\\\\envs\\\\test\\\\lib\\\\site-packages\\\\torch\\\\version.py'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "existing-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from random import randint, expovariate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-spare",
   "metadata": {},
   "source": [
    "- Generate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4462929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_CPU_MAX = []\n",
    "S_BW_MAX = []\n",
    "\n",
    "# 随机生成一个图(20节点, 100链路)\n",
    "net = nx.gnm_random_graph(n=20, m=100)\n",
    "\n",
    "# 设置所有节点的CPU数据, 并同时统计最大值最小值\n",
    "min_cpu_capacity = 1.0e10\n",
    "max_cpu_capacity = 0.0\n",
    "for node_id in net.nodes:\n",
    "    net.nodes[node_id]['CPU'] = randint(50, 100)\n",
    "    net.nodes[node_id]['LOCATION'] = randint(0, 2)\n",
    "    if net.nodes[node_id]['CPU'] < min_cpu_capacity:\n",
    "        min_cpu_capacity = net.nodes[node_id]['CPU']\n",
    "    if net.nodes[node_id]['CPU'] > max_cpu_capacity:\n",
    "        max_cpu_capacity = net.nodes[node_id]['CPU']\n",
    "\n",
    "# 设置链路的带宽数据, 并同时统计最大带宽最小带宽\n",
    "min_bandwidth_capacity = 1.0e10\n",
    "max_bandwidth_capacity = 0.0\n",
    "for edge_id in net.edges:\n",
    "    net.edges[edge_id]['bandwidth'] = randint(50, 100)\n",
    "    if net.edges[edge_id]['bandwidth'] < min_bandwidth_capacity:\n",
    "        min_bandwidth_capacity = net.edges[edge_id]['bandwidth']\n",
    "    if net.edges[edge_id]['bandwidth'] > max_bandwidth_capacity:\n",
    "        max_bandwidth_capacity = net.edges[edge_id]['bandwidth']\n",
    "\n",
    "# data=True: 返回的是 NodeDataView 对象, 该对象不仅包含每个顶点的 ID 属性, 还包括顶点的其他属性\n",
    "for s_node_id, s_node_data in net.nodes(data=True):\n",
    "    S_CPU_MAX.append(s_node_data['CPU'])\n",
    "\n",
    "# 统计每个底层节点周围链路带宽和\n",
    "for s_node_id in range(len(net.nodes)):\n",
    "    total_node_bandwidth = 0.0\n",
    "    for link_id in net[s_node_id]:\n",
    "        total_node_bandwidth += net[s_node_id][link_id]['bandwidth']\n",
    "    S_BW_MAX.append(total_node_bandwidth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "promotional-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    " # S_CPU_Free\n",
    "s_CPU_remaining = []\n",
    "s_bandwidth_remaining = []\n",
    "\n",
    "# 1 表示目前哪些节点被占用, 0 相反\n",
    "current_embedding = [0] * len(net.nodes)\n",
    "\n",
    "# 节点剩余资源\n",
    "for s_node_id, s_node_data in net.nodes(data=True):\n",
    "    s_CPU_remaining.append(s_node_data['CPU'])\n",
    "    \n",
    "# 节点周围剩余带宽资源\n",
    "for s_node_id in range(len(net.nodes)):\n",
    "    total_node_bandwidth = 0.0\n",
    "    for link_id in net[s_node_id]:\n",
    "        total_node_bandwidth += net[s_node_id][link_id]['bandwidth']\n",
    "    s_bandwidth_remaining.append(total_node_bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "speaking-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99, 89, 67, 75, 69, 76, 85, 76, 62, 68, 53, 100, 90, 87, 99, 65, 65, 82, 73, 76], [1033.0, 803.0, 367.0, 660.0, 634.0, 574.0, 638.0, 903.0, 872.0, 799.0, 896.0, 902.0, 1103.0, 632.0, 770.0, 857.0, 933.0, 159.0, 1101.0, 498.0], [99, 89, 67, 75, 69, 76, 85, 76, 62, 68, 53, 100, 90, 87, 99, 65, 65, 82, 73, 76], [1033.0, 803.0, 367.0, 660.0, 634.0, 574.0, 638.0, 903.0, 872.0, 799.0, 896.0, 902.0, 1103.0, 632.0, 770.0, 857.0, 933.0, 159.0, 1101.0, 498.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# 底层网络特征矩阵\n",
    "substrate_features = []\n",
    "substrate_features.append(S_CPU_MAX)\n",
    "substrate_features.append(S_BW_MAX)\n",
    "substrate_features.append(s_CPU_remaining)\n",
    "substrate_features.append(s_bandwidth_remaining)\n",
    "substrate_features.append(current_embedding)\n",
    "\n",
    "print(substrate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "voluntary-favorite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  99.,   89.,   67.,   75.,   69.,   76.,   85.,   76.,   62.,   68.,\n",
      "           53.,  100.,   90.,   87.,   99.,   65.,   65.,   82.,   73.,   76.],\n",
      "        [1033.,  803.,  367.,  660.,  634.,  574.,  638.,  903.,  872.,  799.,\n",
      "          896.,  902., 1103.,  632.,  770.,  857.,  933.,  159., 1101.,  498.],\n",
      "        [  99.,   89.,   67.,   75.,   69.,   76.,   85.,   76.,   62.,   68.,\n",
      "           53.,  100.,   90.,   87.,   99.,   65.,   65.,   82.,   73.,   76.],\n",
      "        [1033.,  803.,  367.,  660.,  634.,  574.,  638.,  903.,  872.,  799.,\n",
      "          896.,  902., 1103.,  632.,  770.,  857.,  933.,  159., 1101.,  498.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])\n",
      "torch.Size([5, 20])\n",
      "tensor([[  99., 1033.,   99., 1033.,    0.],\n",
      "        [  89.,  803.,   89.,  803.,    0.],\n",
      "        [  67.,  367.,   67.,  367.,    0.],\n",
      "        [  75.,  660.,   75.,  660.,    0.],\n",
      "        [  69.,  634.,   69.,  634.,    0.],\n",
      "        [  76.,  574.,   76.,  574.,    0.],\n",
      "        [  85.,  638.,   85.,  638.,    0.],\n",
      "        [  76.,  903.,   76.,  903.,    0.],\n",
      "        [  62.,  872.,   62.,  872.,    0.],\n",
      "        [  68.,  799.,   68.,  799.,    0.],\n",
      "        [  53.,  896.,   53.,  896.,    0.],\n",
      "        [ 100.,  902.,  100.,  902.,    0.],\n",
      "        [  90., 1103.,   90., 1103.,    0.],\n",
      "        [  87.,  632.,   87.,  632.,    0.],\n",
      "        [  99.,  770.,   99.,  770.,    0.],\n",
      "        [  65.,  857.,   65.,  857.,    0.],\n",
      "        [  65.,  933.,   65.,  933.,    0.],\n",
      "        [  82.,  159.,   82.,  159.,    0.],\n",
      "        [  73., 1101.,   73., 1101.,    0.],\n",
      "        [  76.,  498.,   76.,  498.,    0.]])\n",
      "torch.Size([20, 5])\n"
     ]
    }
   ],
   "source": [
    "substrate_features = torch.tensor(substrate_features)\n",
    "print(substrate_features)\n",
    "print(substrate_features.shape)\n",
    "\n",
    "# transpose: 转置\n",
    "substrate_features = torch.transpose(substrate_features, 0, 1)\n",
    "print(substrate_features)\n",
    "print(substrate_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "streaming-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# substrate_features = torch.reshape(substrate_features, (-1,))\n",
    "# print(substrate_features.shape)\n",
    "# print(substrate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "sweet-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vnr_cpu = torch.tensor([10])\n",
    "# vnr_bw = torch.tensor([30])\n",
    "# pending = torch.tensor([2])\n",
    "# substrate_features = torch.cat((substrate_features, vnr_cpu, vnr_bw, pending), 0)\n",
    "\n",
    "# substrate_features\n",
    "# substrate_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "considered-literacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  99., 1033.,   99., 1033.,    0.],\n",
      "        [  89.,  803.,   89.,  803.,    0.],\n",
      "        [  67.,  367.,   67.,  367.,    0.],\n",
      "        [  75.,  660.,   75.,  660.,    0.],\n",
      "        [  69.,  634.,   69.,  634.,    0.],\n",
      "        [  76.,  574.,   76.,  574.,    0.],\n",
      "        [  85.,  638.,   85.,  638.,    0.],\n",
      "        [  76.,  903.,   76.,  903.,    0.],\n",
      "        [  62.,  872.,   62.,  872.,    0.],\n",
      "        [  68.,  799.,   68.,  799.,    0.],\n",
      "        [  53.,  896.,   53.,  896.,    0.],\n",
      "        [ 100.,  902.,  100.,  902.,    0.],\n",
      "        [  90., 1103.,   90., 1103.,    0.],\n",
      "        [  87.,  632.,   87.,  632.,    0.],\n",
      "        [  99.,  770.,   99.,  770.,    0.],\n",
      "        [  65.,  857.,   65.,  857.,    0.],\n",
      "        [  65.,  933.,   65.,  933.,    0.],\n",
      "        [  82.,  159.,   82.,  159.,    0.],\n",
      "        [  73., 1101.,   73., 1101.,    0.],\n",
      "        [  76.,  498.,   76.,  498.,    0.]])\n"
     ]
    }
   ],
   "source": [
    "print(substrate_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-brick",
   "metadata": {},
   "source": [
    "- Using 'from_networkx'\n",
    "    - transfer the torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "capital-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = from_networkx(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "needed-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 200], CPU=[20], LOCATION=[20], bandwidth=[200], num_nodes=20)\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-relief",
   "metadata": {},
   "source": [
    "### Graph Convolution Network\n",
    "- Generate the GCN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "better-awareness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(5, 4)\n",
      "  (conv2): GCNConv(4, 4)\n",
      "  (conv3): GCNConv(4, 1)\n",
      "  (classifier): Linear(in_features=1, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        # in_channels: 节点特征数   out_channels: 输出的节点分类数\n",
    "        self.conv1 = GCNConv(in_channels=5, out_channels=4)\n",
    "        self.conv2 = GCNConv(in_channels=4, out_channels=4)\n",
    "        self.conv3 = GCNConv(in_channels=4, out_channels=1)\n",
    "        self.classifier = Linear(1, 20)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h\n",
    "\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "liberal-student",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5]) torch.Size([2, 200])\n",
      "tensor([[  99., 1033.,   99., 1033.,    0.],\n",
      "        [  89.,  803.,   89.,  803.,    0.],\n",
      "        [  67.,  367.,   67.,  367.,    0.],\n",
      "        [  75.,  660.,   75.,  660.,    0.],\n",
      "        [  69.,  634.,   69.,  634.,    0.],\n",
      "        [  76.,  574.,   76.,  574.,    0.],\n",
      "        [  85.,  638.,   85.,  638.,    0.],\n",
      "        [  76.,  903.,   76.,  903.,    0.],\n",
      "        [  62.,  872.,   62.,  872.,    0.],\n",
      "        [  68.,  799.,   68.,  799.,    0.],\n",
      "        [  53.,  896.,   53.,  896.,    0.],\n",
      "        [ 100.,  902.,  100.,  902.,    0.],\n",
      "        [  90., 1103.,   90., 1103.,    0.],\n",
      "        [  87.,  632.,   87.,  632.,    0.],\n",
      "        [  99.,  770.,   99.,  770.,    0.],\n",
      "        [  65.,  857.,   65.,  857.,    0.],\n",
      "        [  65.,  933.,   65.,  933.,    0.],\n",
      "        [  82.,  159.,   82.,  159.,    0.],\n",
      "        [  73., 1101.,   73., 1101.,    0.],\n",
      "        [  76.,  498.,   76.,  498.,    0.]])\n",
      "Embedding shape: [20, 1]\n"
     ]
    }
   ],
   "source": [
    "model = GCN()\n",
    "\n",
    "print(substrate_features.shape, data.edge_index.shape)\n",
    "print(substrate_features)\n",
    "\n",
    "out, embedding = model(substrate_features, data.edge_index)\n",
    "# out, embedding = model(data.x, data.edge_index)\n",
    "print(f'Embedding shape: {list(embedding.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "indoor-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7949],\n",
      "        [0.7536],\n",
      "        [0.6288],\n",
      "        [0.7303],\n",
      "        [0.7094],\n",
      "        [0.7234],\n",
      "        [0.7230],\n",
      "        [0.8206],\n",
      "        [0.7859],\n",
      "        [0.7537],\n",
      "        [0.7836],\n",
      "        [0.7870],\n",
      "        [0.8120],\n",
      "        [0.7117],\n",
      "        [0.7662],\n",
      "        [0.7857],\n",
      "        [0.7831],\n",
      "        [0.5692],\n",
      "        [0.8311],\n",
      "        [0.6881]], grad_fn=<TanhBackward0>)\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "print(embedding)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "expressed-ottawa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20])\n",
      "tensor([[-0.9015,  0.0903,  0.1798, -0.8786,  0.4872, -1.5868,  0.3313, -0.5921,\n",
      "         -1.6528, -0.0988, -0.5320, -0.9747,  0.2216,  0.6303,  0.3589, -0.2516,\n",
      "         -0.3022, -0.4172, -0.3885,  0.6563],\n",
      "        [-0.9013,  0.0649,  0.2164, -0.8465,  0.4948, -1.5459,  0.3257, -0.5628,\n",
      "         -1.6157, -0.0820, -0.5099, -0.9745,  0.1939,  0.6404,  0.3506, -0.2702,\n",
      "         -0.3133, -0.4192, -0.3953,  0.6319],\n",
      "        [-0.9007, -0.0118,  0.3269, -0.7498,  0.5176, -1.4221,  0.3088, -0.4744,\n",
      "         -1.5036, -0.0313, -0.4430, -0.9738,  0.1103,  0.6708,  0.3258, -0.3266,\n",
      "         -0.3469, -0.4254, -0.4156,  0.5585],\n",
      "        [-0.9012,  0.0506,  0.2371, -0.8284,  0.4991, -1.5227,  0.3226, -0.5463,\n",
      "         -1.5947, -0.0725, -0.4973, -0.9744,  0.1782,  0.6461,  0.3460, -0.2808,\n",
      "         -0.3196, -0.4204, -0.3991,  0.6182],\n",
      "        [-0.9011,  0.0378,  0.2555, -0.8123,  0.5029, -1.5021,  0.3197, -0.5315,\n",
      "         -1.5760, -0.0641, -0.4862, -0.9743,  0.1643,  0.6511,  0.3419, -0.2902,\n",
      "         -0.3252, -0.4214, -0.4025,  0.6059],\n",
      "        [-0.9011,  0.0463,  0.2432, -0.8231,  0.5003, -1.5159,  0.3216, -0.5414,\n",
      "         -1.5885, -0.0697, -0.4937, -0.9743,  0.1736,  0.6477,  0.3446, -0.2839,\n",
      "         -0.3215, -0.4207, -0.4002,  0.6141],\n",
      "        [-0.9011,  0.0461,  0.2435, -0.8228,  0.5004, -1.5155,  0.3216, -0.5412,\n",
      "         -1.5882, -0.0696, -0.4935, -0.9743,  0.1734,  0.6478,  0.3446, -0.2840,\n",
      "         -0.3216, -0.4207, -0.4003,  0.6139],\n",
      "        [-0.9016,  0.1061,  0.1570, -0.8985,  0.4825, -1.6123,  0.3348, -0.6103,\n",
      "         -1.6758, -0.1092, -0.5458, -0.9748,  0.2388,  0.6241,  0.3640, -0.2400,\n",
      "         -0.2953, -0.4159, -0.3843,  0.6714],\n",
      "        [-0.9014,  0.0848,  0.1877, -0.8716,  0.4889, -1.5779,  0.3301, -0.5857,\n",
      "         -1.6447, -0.0951, -0.5272, -0.9746,  0.2156,  0.6325,  0.3571, -0.2556,\n",
      "         -0.3047, -0.4176, -0.3900,  0.6510],\n",
      "        [-0.9013,  0.0649,  0.2163, -0.8466,  0.4948, -1.5459,  0.3257, -0.5629,\n",
      "         -1.6157, -0.0820, -0.5099, -0.9745,  0.1939,  0.6404,  0.3507, -0.2702,\n",
      "         -0.3133, -0.4192, -0.3953,  0.6320],\n",
      "        [-0.9014,  0.0834,  0.1898, -0.8698,  0.4893, -1.5756,  0.3298, -0.5841,\n",
      "         -1.6426, -0.0942, -0.5260, -0.9746,  0.2140,  0.6331,  0.3566, -0.2567,\n",
      "         -0.3053, -0.4178, -0.3904,  0.6496],\n",
      "        [-0.9014,  0.0854,  0.1868, -0.8724,  0.4887, -1.5789,  0.3303, -0.5864,\n",
      "         -1.6456, -0.0956, -0.5277, -0.9747,  0.2163,  0.6322,  0.3573, -0.2552,\n",
      "         -0.3044, -0.4176, -0.3898,  0.6516],\n",
      "        [-0.9015,  0.1008,  0.1647, -0.8918,  0.4841, -1.6037,  0.3337, -0.6041,\n",
      "         -1.6680, -0.1057, -0.5411, -0.9748,  0.2330,  0.6262,  0.3623, -0.2439,\n",
      "         -0.2977, -0.4164, -0.3858,  0.6663],\n",
      "        [-0.9011,  0.0392,  0.2534, -0.8141,  0.5025, -1.5044,  0.3200, -0.5332,\n",
      "         -1.5781, -0.0650, -0.4874, -0.9743,  0.1658,  0.6506,  0.3423, -0.2891,\n",
      "         -0.3246, -0.4213, -0.4021,  0.6073],\n",
      "        [-0.9013,  0.0727,  0.2052, -0.8563,  0.4925, -1.5583,  0.3274, -0.5717,\n",
      "         -1.6270, -0.0871, -0.5166, -0.9745,  0.2023,  0.6373,  0.3532, -0.2645,\n",
      "         -0.3100, -0.4186, -0.3932,  0.6393],\n",
      "        [-0.9014,  0.0846,  0.1879, -0.8714,  0.4889, -1.5777,  0.3301, -0.5856,\n",
      "         -1.6445, -0.0951, -0.5271, -0.9746,  0.2154,  0.6325,  0.3570, -0.2557,\n",
      "         -0.3047, -0.4177, -0.3900,  0.6508],\n",
      "        [-0.9014,  0.0830,  0.1902, -0.8694,  0.4894, -1.5751,  0.3297, -0.5837,\n",
      "         -1.6421, -0.0940, -0.5257, -0.9746,  0.2137,  0.6332,  0.3565, -0.2569,\n",
      "         -0.3054, -0.4178, -0.3905,  0.6493],\n",
      "        [-0.9004, -0.0484,  0.3797, -0.7036,  0.5285, -1.3631,  0.3007, -0.4323,\n",
      "         -1.4502, -0.0071, -0.4111, -0.9735,  0.0703,  0.6853,  0.3139, -0.3535,\n",
      "         -0.3630, -0.4283, -0.4254,  0.5234],\n",
      "        [-0.9016,  0.1125,  0.1477, -0.9066,  0.4806, -1.6227,  0.3363, -0.6177,\n",
      "         -1.6852, -0.1135, -0.5514, -0.9749,  0.2458,  0.6215,  0.3661, -0.2352,\n",
      "         -0.2925, -0.4154, -0.3826,  0.6776],\n",
      "        [-0.9010,  0.0246,  0.2744, -0.7957,  0.5068, -1.4809,  0.3168, -0.5164,\n",
      "         -1.5568, -0.0554, -0.4747, -0.9741,  0.1500,  0.6563,  0.3376, -0.2998,\n",
      "         -0.3310, -0.4225, -0.4060,  0.5933]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-chess",
   "metadata": {},
   "source": [
    "# A3C Code\n",
    "- Simple A3C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def v_wrap(np_array, dtype=np.float32):\n",
    "    if np_array.dtype != dtype:\n",
    "        np_array = np_array.astype(dtype)\n",
    "    return torch.from_numpy(np_array)\n",
    "\n",
    "\n",
    "def set_init(layers):\n",
    "    for layer in layers:\n",
    "        nn.init.normal_(layer.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(layer.bias, 0.)\n",
    "\n",
    "\n",
    "def push_and_pull(opt, lnet, gnet, done, s_, bs, buffer_action, buffer_reward, gamma):\n",
    "    if done:\n",
    "        v_s_ = 0.               # terminal\n",
    "    else:\n",
    "        v_s_ = lnet.forward(v_wrap(s_[None, :]))[-1].data.numpy()[0, 0]\n",
    "\n",
    "    buffer_v_target = []\n",
    "    for r in buffer_reward[::-1]:    # reverse buffer r\n",
    "        v_s_ = r + gamma * v_s_\n",
    "        buffer_v_target.append(v_s_)\n",
    "    buffer_v_target.reverse()\n",
    "    loss = lnet.loss_func(\n",
    "        v_wrap(np.vstack(bs)),\n",
    "        v_wrap(np.array(buffer_action), dtype=np.int64) if buffer_action[0].dtype == np.int64 else v_wrap(np.vstack(buffer_action)),\n",
    "        v_wrap(np.array(buffer_v_target)[:, None]))\n",
    "\n",
    "    # calculate local gradients and push local parameters to global\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    for lp, gp in zip(lnet.parameters(), gnet.parameters()):\n",
    "        gp._grad = lp.grad\n",
    "    opt.step()\n",
    "\n",
    "    # pull global parameters\n",
    "    lnet.load_state_dict(gnet.state_dict())\n",
    "\n",
    "\n",
    "def record(global_ep, global_ep_r, ep_r, res_queue, name):\n",
    "    with global_ep.get_lock():\n",
    "        global_ep.value += 1\n",
    "    with global_ep_r.get_lock():\n",
    "        if global_ep_r.value == 0.:\n",
    "            global_ep_r.value = ep_r\n",
    "        else:\n",
    "            global_ep_r.value = global_ep_r.value * 0.99 + ep_r * 0.01\n",
    "    res_queue.put(global_ep_r.value)\n",
    "    print(\n",
    "        name,\n",
    "        \"Ep:\", global_ep.value,\n",
    "        \"| Ep_r: %.0f\" % global_ep_r.value,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedAdam(torch.optim.Adam):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.99), eps=1e-8,\n",
    "                 weight_decay=0):\n",
    "        super(SharedAdam, self).__init__(params, lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        # State initialization\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                state['step'] = 0\n",
    "                state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "\n",
    "                # share in memory\n",
    "                state['exp_avg'].share_memory_()\n",
    "                state['exp_avg_sq'].share_memory_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import gym\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "UPDATE_GLOBAL_ITER = 5\n",
    "GAMMA = 0.9\n",
    "MAX_EP = 3000\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "N_S = env.observation_space.shape[0]\n",
    "N_A = env.action_space.n\n",
    "\n",
    "print(N_S, N_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.s_dim = s_dim\n",
    "        self.a_dim = a_dim\n",
    "        self.pi1 = nn.Linear(s_dim, 128)\n",
    "        self.pi2 = nn.Linear(128, a_dim)\n",
    "        self.v1 = nn.Linear(s_dim, 128)\n",
    "        self.v2 = nn.Linear(128, 1)\n",
    "        set_init([self.pi1, self.pi2, self.v1, self.v2])\n",
    "        self.distribution = torch.distributions.Categorical\n",
    "\n",
    "    def forward(self, x):\n",
    "        pi1 = torch.tanh(self.pi1(x))\n",
    "        logits = self.pi2(pi1)\n",
    "        v1 = torch.tanh(self.v1(x))\n",
    "        values = self.v2(v1)\n",
    "        return logits, values\n",
    "\n",
    "    def choose_action(self, s):\n",
    "        self.eval()\n",
    "        logits, _ = self.forward(s)\n",
    "        prob = F.softmax(logits, dim=1).data\n",
    "        m = self.distribution(prob)\n",
    "        return m.sample().numpy()[0]\n",
    "\n",
    "    def loss_func(self, s, a, v_t):\n",
    "        self.train()\n",
    "        logits, values = self.forward(s)\n",
    "        td = v_t - values\n",
    "        c_loss = td.pow(2)\n",
    "        \n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        m = self.distribution(probs)\n",
    "        exp_v = m.log_prob(a) * td.detach().squeeze()\n",
    "        a_loss = -exp_v\n",
    "        total_loss = (c_loss + a_loss).mean()\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(mp.Process):\n",
    "    def __init__(self, gnet, opt, global_ep, global_ep_r, res_queue, name):\n",
    "        super(Worker, self).__init__()\n",
    "        self.name = 'w%02i' % name\n",
    "        self.g_ep, self.g_ep_r, self.res_queue = global_ep, global_ep_r, res_queue\n",
    "        self.gnet, self.opt = gnet, opt\n",
    "        self.lnet = Net(N_S, N_A)           # local network\n",
    "        self.env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "    def run(self):\n",
    "        total_step = 1\n",
    "        while self.g_ep.value < MAX_EP:\n",
    "            s = self.env.reset()\n",
    "            buffer_s, buffer_action, buffer_reward = [], [], []\n",
    "            ep_r = 0.\n",
    "            while True:\n",
    "#                 if self.name == 'w00':\n",
    "#                     self.env.render()\n",
    "                print(s)\n",
    "                a = self.lnet.choose_action(v_wrap(s[None, :]))\n",
    "                print(s[None, :])\n",
    "                print(v_wrap(s[None, :]))\n",
    "                s_, r, done, _ = self.env.step(a)\n",
    "                if done: r = -1\n",
    "                ep_r += r\n",
    "                buffer_action.append(a)\n",
    "                buffer_s.append(s)\n",
    "                buffer_reward.append(r)\n",
    "\n",
    "                if total_step % UPDATE_GLOBAL_ITER == 0 or done:  # update global and assign to local net\n",
    "                    # sync\n",
    "                    push_and_pull(self.opt, self.lnet, self.gnet, done, s_, buffer_s, buffer_action, buffer_reward, GAMMA)\n",
    "                    buffer_s, buffer_action, buffer_reward = [], [], []\n",
    "\n",
    "                    if done:  # done and print information\n",
    "                        record(self.g_ep, self.g_ep_r, ep_r, self.res_queue, self.name)\n",
    "                        break\n",
    "                s = s_\n",
    "                total_step += 1\n",
    "        self.res_queue.put(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnet = Net(N_S, N_A)        # global network\n",
    "gnet.share_memory()         # share the global parameters in multiprocessing\n",
    "opt = SharedAdam(gnet.parameters(), lr=1e-4, betas=(0.92, 0.999))      # global optimizer\n",
    "global_ep, global_ep_r, res_queue = mp.Value('i', 0), mp.Value('d', 0.), mp.Queue()\n",
    "print(mp.cpu_count())\n",
    "\n",
    "# parallel training\n",
    "workers = [Worker(gnet, opt, global_ep, global_ep_r, res_queue, i) for i in range(mp.cpu_count())]\n",
    "[w.start() for w in workers]\n",
    "res = []                    # record episode reward to plot\n",
    "while True:\n",
    "    r = res_queue.get()\n",
    "    if r is not None:\n",
    "        res.append(r)\n",
    "    else:\n",
    "        break\n",
    "[w.join() for w in workers]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(res)\n",
    "plt.ylabel('Moving average ep reward')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-pulse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-stocks",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "672febc8a634011916ed982843df2ba95c600e4486f28df059bab71366202ec7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
